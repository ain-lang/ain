"""
Corpus Sync: ì£¼ê¸°ì  ìƒíƒœ ë™ê¸°í™”
"""
import hashlib
import asyncio
from datetime import datetime
from typing import List, Dict, Optional

try:
    import pyarrow as pa
    HAS_ARROW = True
except ImportError:
    HAS_ARROW = False

try:
    from database.serializer import GraphSerializer
    HAS_SERIALIZER = True
except ImportError:
    HAS_SERIALIZER = False


class SyncMixin:
    """ë™ê¸°í™” ë¯¹ìŠ¤ì¸ - CorpusCallosumì—ì„œ ì‚¬ìš©"""
    
    async def sync_pulse(self) -> bool:
        """ì‹¤í–‰ ì£¼ê¸°ë§ˆë‹¤ ìƒíƒœë¥¼ Arrow Batchë¡œ ì§ë ¬í™”í•˜ì—¬ ì˜êµ¬ ì €ì¥"""
        sync_start = datetime.now()
        results = []
        
        try:
            # ì¢Œë‡Œ ë™ê¸°í™”: FactCore â†’ SurrealDB
            if self._bridge_connected and self.bridge:
                fact_result = await self._sync_fact_nodes()
                results.append(("FactCoreâ†’SurrealDB", fact_result))
            else:
                results.append(("FactCoreâ†’SurrealDB", False))
            
            # ì¢Œë‡Œ ë™ê¸°í™”: Nexus â†’ SurrealDB
            if self._bridge_connected and self.bridge:
                nexus_result = await self._sync_nexus_memory()
                results.append(("Nexusâ†’SurrealDB", nexus_result))
            else:
                results.append(("Nexusâ†’SurrealDB", False))
            
            # ìš°ë‡Œ ë™ê¸°í™”: Evolution â†’ LanceDB
            if self._vector_connected and self.vector_bridge:
                semantic_result = await self._sync_semantic_memory()
                results.append(("Evolutionâ†’LanceDB", semantic_result))
            else:
                results.append(("Evolutionâ†’LanceDB", False))
            
            self._last_sync_time = sync_start
            self._sync_count += 1
            
            success_count = sum(1 for _, r in results if r)
            result_summary = " | ".join([f"{name}: {'âœ“' if ok else 'âœ—'}" for name, ok in results])
            print(f"ğŸ”„ Sync Pulse #{self._sync_count} ì™„ë£Œ: {success_count}/{len(results)} ì„±ê³µ [{result_summary}]")
            
            return success_count > 0
            
        except Exception as e:
            print(f"âŒ Sync Pulse ì‹¤íŒ¨: {e}")
            return False

    async def _sync_fact_nodes(self) -> bool:
        """FactCore ë…¸ë“œ/ì—£ì§€ë¥¼ SurrealDBì— ë™ê¸°í™”"""
        try:
            if HAS_SERIALIZER:
                node_table = GraphSerializer.nodes_to_table(self.left_brain.nodes)
            else:
                node_table = self.format_fact_for_surreal()
                
            if node_table and node_table.num_rows > 0:
                await asyncio.to_thread(self.bridge.push_batch_sync, node_table, "node")
                print(f"  â””â”€ FactCore Nodes: {node_table.num_rows}ê°œ ë™ê¸°í™”ë¨")
            
            if HAS_SERIALIZER:
                edge_table = GraphSerializer.edges_to_table(self.left_brain.nodes)
                if edge_table and edge_table.num_rows > 0:
                    await asyncio.to_thread(self.bridge.push_batch_sync, edge_table, "relation")
                    print(f"  â””â”€ FactCore Edges: {edge_table.num_rows}ê°œ ë™ê¸°í™”ë¨")
            
            return True
            
        except Exception as e:
            print(f"âŒ FactCore ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def _sync_nexus_memory(self) -> bool:
        """Nexus ì§„í™” ê¸°ë¡ì„ SurrealDBì— ë™ê¸°í™”"""
        try:
            if hasattr(self.right_brain, '_evolution_history_cache'):
                history = self.right_brain._evolution_history_cache
            else:
                history = []
            
            if not history:
                return True
            
            history_table = self._history_to_arrow(history)
            if history_table and history_table.num_rows > 0:
                await asyncio.to_thread(self.bridge.push_batch_sync, history_table, "evolution_history")
                print(f"  â””â”€ Nexus History: {history_table.num_rows}ê°œ ë™ê¸°í™”ë¨")
            
            return True
            
        except Exception as e:
            print(f"âŒ Nexus ë©”ëª¨ë¦¬ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def _sync_semantic_memory(self) -> bool:
        """ì§„í™” ê¸°ë¡ì„ LanceDBì— ë²¡í„°í™”í•˜ì—¬ ì €ì¥"""
        if not self.vector_bridge or not self._vector_connected:
            return False
        
        try:
            if hasattr(self.right_brain, '_evolution_history_cache'):
                full_history = self.right_brain._evolution_history_cache
            else:
                full_history = []
            
            if not full_history:
                return True
            
            new_records = full_history[self._last_synced_evolution_index:]
            
            if not new_records:
                return True
            
            success_count = 0
            for record in new_records:
                try:
                    description = record.get('description', '')
                    if not description:
                        continue
                    
                    metadata = {
                        "timestamp": record.get('timestamp', ''),
                        "type": record.get('type', 'EVOLUTION'),
                        "action": record.get('action', 'Unknown'),
                        "file": record.get('file', ''),
                        "status": record.get('status', 'unknown'),
                    }
                    
                    if hasattr(self.right_brain, '_generate_embedding'):
                        vector = self.right_brain._generate_embedding(description)
                    else:
                        vector = self._generate_placeholder_embedding(description)
                    
                    stored = self.vector_bridge.add_memory(
                        text=description,
                        vector=vector,
                        memory_type="evolution",
                        source="evolution_history",
                        metadata=metadata
                    )
                    
                    if stored:
                        success_count += 1
                        
                except Exception as e:
                    continue
            
            self._last_synced_evolution_index = len(full_history)
            print(f"  â””â”€ Semantic Memory: {success_count}/{len(new_records)}ê°œ ë²¡í„°í™” ì™„ë£Œ")
            return success_count > 0
            
        except Exception as e:
            print(f"âŒ Semantic Memory ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def _generate_placeholder_embedding(self, text: str) -> List[float]:
        """Placeholder ì„ë² ë”© ìƒì„±"""
        text_hash = hashlib.sha256(text.encode('utf-8')).hexdigest()
        
        vector = []
        for i in range(0, min(len(text_hash), self.EMBEDDING_DIM * 2), 2):
            byte_val = int(text_hash[i:i+2], 16)
            normalized = (byte_val - 128) / 128.0
            vector.append(normalized)
        
        while len(vector) < self.EMBEDDING_DIM:
            idx = len(vector) % len(vector) if vector else 0
            vector.append(vector[idx] * 0.9 if vector else 0.0)
        
        return vector[:self.EMBEDDING_DIM]

    def sync_facts_to_surreal(self) -> bool:
        """FactCore ë™ê¸°í™” (ë™ê¸° ë²„ì „)"""
        if not self.bridge or not self._bridge_connected:
            return False
        
        try:
            node_table = self.format_fact_for_surreal()
            if node_table:
                self.bridge.push_batch_sync(node_table, "node")
                self._sync_count += 1
                self._last_sync_time = datetime.now()
                return True
            return False
        except Exception as e:
            print(f"âŒ sync_facts_to_surreal ì‹¤íŒ¨: {e}")
            return False
