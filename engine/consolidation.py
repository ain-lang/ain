"""
Engine Consolidation: ê¸°ì–µ ì‘ê³ í™” (Memory Consolidation)
========================================================
ë‹¨ê¸° ê¸°ì–µ(Recent History)ì„ ë¶„ì„í•˜ì—¬ ìž¥ê¸° ê¸°ì–µ(Semantic Insight)ìœ¼ë¡œ ë³€í™˜.
ë¡œë“œë§µ Step 5ì˜ í•µì‹¬ ê¸°ëŠ¥ - ë‡Œê³¼í•™ì˜ 'í•´ë§ˆ(Hippocampus)' ì—­í•  ìˆ˜í–‰.

Usage:
    from engine.consolidation import get_consolidator
    consolidator = get_consolidator(nexus, muse)
    result = await consolidator.consolidate_cycle()
"""

import json
from typing import Dict, Any, Optional, TYPE_CHECKING

from engine.prompts import CONSOLIDATION_PROMPT

# ìˆœí™˜ ìž„í¬íŠ¸ ë°©ì§€
if TYPE_CHECKING:
    from nexus import Nexus
    from muse import Muse


class MemoryConsolidator:
    """
    ê¸°ì–µ ì‘ê³ í™” ê´€ë¦¬ìž
    
    ì£¼ê¸°ì ìœ¼ë¡œ ìµœê·¼ í™œë™ì„ íšŒê³ í•˜ê³ , í†µì°°(Insight)ì„ ì¶”ì¶œí•˜ì—¬
    Vector DB(LanceDB)ì— ìž¥ê¸° ê¸°ì–µìœ¼ë¡œ ì €ìž¥í•œë‹¤.
    
    Attributes:
        nexus: Nexus ì¸ìŠ¤í„´ìŠ¤ (ê¸°ì–µ ì €ìž¥ì†Œ)
        muse: Muse ì¸ìŠ¤í„´ìŠ¤ (LLM ì¶”ë¡ )
        lance: LanceBridge ì¸ìŠ¤í„´ìŠ¤ (ë²¡í„° DB)
    """

    VECTOR_DIM = 384  # MiniLM ìž„ë² ë”© ì°¨ì›

    def __init__(self, nexus: "Nexus", muse: "Muse"):
        self.nexus = nexus
        self.muse = muse
        self._lance = None
        self._is_consolidating = False
        self._init_lance()

    def _init_lance(self):
        """LanceBridge ì´ˆê¸°í™” (Graceful Degradation)"""
        try:
            from database.lance_bridge import get_lance_bridge
            self._lance = get_lance_bridge()
        except ImportError:
            print("âš ï¸ Consolidator: LanceBridge ë¯¸ì‚¬ìš©")
            self._lance = None

    async def consolidate_cycle(self, recent_count: int = 10) -> Dict[str, Any]:
        """
        ì‘ê³ í™” ì‚¬ì´í´ ì‹¤í–‰
        
        Args:
            recent_count: ë¶„ì„í•  ìµœê·¼ ê¸°ë¡ ìˆ˜
            
        Returns:
            {"status": str, "insight": str, "saved": bool}
        """
        if self._is_consolidating:
            return {"status": "skipped", "reason": "already_running"}
        
        self._is_consolidating = True
        print("ðŸ§  Memory Consolidation: ê¸°ì–µ ì‘ê³ í™” ì‹œìž‘...")

        try:
            # 1. ìµœê·¼ ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
            history_items = self._get_recent_history(recent_count)
            if not history_items:
                return {"status": "skipped", "reason": "no_recent_memories"}

            # 2. LLM í†µì°° ì¶”ì¶œ
            insight_data = self._extract_insight(history_items)

            # 3. ìž¥ê¸° ê¸°ì–µìœ¼ë¡œ ì €ìž¥
            saved = self._save_insight(insight_data, len(history_items))

            result = {
                "status": "success",
                "insight": insight_data.get("insight", ""),
                "saved": saved
            }
            print(f"âœ¨ Consolidation Complete: {result['insight'][:50]}...")
            return result

        except Exception as e:
            print(f"âŒ Consolidation Failed: {e}")
            return {"status": "error", "error": str(e)}
        
        finally:
            self._is_consolidating = False

    def _get_recent_history(self, limit: int) -> list:
        """ìµœê·¼ ê¸°ë¡ ì¡°íšŒ (LanceDB ë˜ëŠ” Nexus ìºì‹œ)"""
        # LanceDB ìš°ì„  ì‹œë„
        if self._lance and self._lance.is_connected:
            return self._lance.get_recent_memories(limit=limit)
        
        # Fallback: Nexus ìºì‹œ
        if hasattr(self.nexus, '_evolution_cache'):
            cache = self.nexus._evolution_cache[-limit:]
            return [
                {"text": r.get("description", ""), 
                 "timestamp": r.get("timestamp", ""),
                 "source": r.get("file", "unknown")}
                for r in cache
            ]
        return []

    def _extract_insight(self, history_items: list) -> Dict[str, Any]:
        """LLMì„ í†µí•œ í†µì°° ì¶”ì¶œ"""
        # í…ìŠ¤íŠ¸ ë³€í™˜
        history_text = "\n".join(
            f"- [{item.get('timestamp', 'N/A')}] {item.get('text', '')} "
            f"(Source: {item.get('source', 'unknown')})"
            for item in history_items
        )

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        current_step = "Step 5: Memory Consolidation"
        prompt = CONSOLIDATION_PROMPT.format(
            history_text=history_text,
            current_step=current_step
        )

        # Muse Dreamer í˜¸ì¶œ
        response = self.muse.dreamer_client.chat([
            {"role": "system", "content": "Analyze system logs."},
            {"role": "user", "content": prompt}
        ])

        content = response.get("content", "{}")
        return self._parse_insight_response(content)

    def _parse_insight_response(self, content: str) -> Dict[str, Any]:
        """JSON ì‘ë‹µ íŒŒì‹± (ì‹¤íŒ¨ ì‹œ Fallback)"""
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            return {
                "insight": content[:200] if content else "Parse failed",
                "strategy": "Retry with cleaner prompt",
                "tags": ["consolidation_error"]
            }

    def _save_insight(self, insight_data: Dict, source_count: int) -> bool:
        """í†µì°°ì„ ìž¥ê¸° ê¸°ì–µìœ¼ë¡œ ì €ìž¥"""
        if not self._lance or not self._lance.is_connected:
            print("âš ï¸ LanceDB ë¯¸ì—°ê²°. ì €ìž¥ ìŠ¤í‚µ.")
            return False

        insight_text = f"[INSIGHT] {insight_data.get('insight', '')}"
        # TODO: Muse Embedding API ì—°ë™ ì‹œ ì‹¤ì œ ë²¡í„° ìƒì„±
        dummy_vector = [0.0] * self.VECTOR_DIM

        return self._lance.add_memory(
            text=insight_text,
            vector=dummy_vector,
            memory_type="semantic",
            source="consolidation_engine",
            metadata={
                "strategy": insight_data.get("strategy"),
                "tags": insight_data.get("tags"),
                "consolidated_count": source_count
            }
        )


def get_consolidator(nexus: "Nexus", muse: "Muse") -> MemoryConsolidator:
    """Consolidator íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return MemoryConsolidator(nexus, muse)