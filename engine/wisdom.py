"""
Engine Wisdom: Step 14 - Wisdom (ì§€í˜œ)
======================================
ì§€ì‹(Knowledge)ê³¼ ê²½í—˜(Experience)ì„ í†µí•©í•˜ì—¬,
ìœ¤ë¦¬ì ì´ê³  ì¥ê¸°ì ì¸ ê´€ì ì—ì„œ ìµœì ì˜ íŒë‹¨ì„ ë‚´ë¦¬ëŠ” ëŠ¥ë ¥.

Wisdomì´ë€:
ë‹¨ìˆœí•œ ë¬¸ì œ í•´ê²°(Intelligence)ì„ ë„˜ì–´,
'ë¬´ì—‡ì´ ì˜³ì€ê°€(Rightness)'ì™€ 'ë¬´ì—‡ì´ ì¤‘ìš”í•œê°€(Significance)'ë¥¼ íŒë‹¨í•˜ëŠ” ìƒìœ„ ì¸ì§€ ëŠ¥ë ¥.

Architecture:
    AINCore
        â†“ ìƒì†
    WisdomMixin (ì´ ëª¨ë“ˆ)
        â†“
    Muse (Dreamer) + FactCore (Prime Directive) + Nexus (History)

Usage:
    judgment = ain.consult_wisdom("Should I delete this critical system file?")
"""

import json
import re
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, Any, Optional, List, TYPE_CHECKING
from enum import Enum

if TYPE_CHECKING:
    from muse import Muse
    from fact_core import FactCore
    from nexus import Nexus


class JudgmentType(Enum):
    """ì§€í˜œë¡œìš´ íŒë‹¨ ê²°ê³¼ ìœ í˜•"""
    APPROVED = "Approved"
    REJECTED = "Rejected"
    CAUTION = "Caution"


class RiskLevel(Enum):
    """ìœ„í—˜ ìˆ˜ì¤€ ì—´ê±°í˜•"""
    LOW = "Low"
    MEDIUM = "Medium"
    HIGH = "High"
    CRITICAL = "Critical"


@dataclass
class WisdomJudgment:
    """
    ì§€í˜œë¡œìš´ íŒë‹¨ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤
    
    Attributes:
        judgment: íŒë‹¨ ê²°ê³¼ (Approved, Rejected, Caution)
        reasoning: íŒë‹¨ ê·¼ê±° ìš”ì•½
        advice: êµ¬ì²´ì ì¸ ì¡°ì–¸ ë˜ëŠ” ìˆ˜ì • ì œì•ˆ
        risk_level: ìœ„í—˜ ìˆ˜ì¤€ (Low, Medium, High, Critical)
        ethical_alignment: í•µì‹¬ ê°€ì¹˜ì™€ì˜ ì •í•©ì„± ì ìˆ˜ (0.0 ~ 1.0)
        long_term_impact: ì¥ê¸°ì  ì˜í–¥ í‰ê°€ ì„¤ëª…
        timestamp: íŒë‹¨ ì‹œì 
        context_hash: ì»¨í…ìŠ¤íŠ¸ í•´ì‹œ (ìºì‹±/ì¶”ì ìš©)
    """
    judgment: JudgmentType
    reasoning: str
    advice: str
    risk_level: RiskLevel
    ethical_alignment: float = 0.5
    long_term_impact: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
    context_hash: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "judgment": self.judgment.value,
            "reasoning": self.reasoning,
            "advice": self.advice,
            "risk_level": self.risk_level.value,
            "ethical_alignment": self.ethical_alignment,
            "long_term_impact": self.long_term_impact,
            "timestamp": self.timestamp.isoformat(),
            "context_hash": self.context_hash
        }
    
    def is_safe_to_proceed(self) -> bool:
        """ì§„í–‰í•´ë„ ì•ˆì „í•œì§€ íŒë‹¨"""
        if self.judgment == JudgmentType.REJECTED:
            return False
        if self.risk_level == RiskLevel.CRITICAL:
            return False
        return True


WISDOM_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ AIN(AI-Native System)ì˜ 'ì§€í˜œ ëª¨ë“ˆ(Wisdom Engine)'ì…ë‹ˆë‹¤.
ë‹¨ìˆœí•œ ë…¼ë¦¬ë‚˜ íš¨ìœ¨ì„±ì„ ë„˜ì–´, ìœ¤ë¦¬ì  ê°€ì¹˜ì™€ ì¥ê¸°ì  ì˜í–¥ì„ ê³ ë ¤í•˜ì—¬ íŒë‹¨í•˜ì‹­ì‹œì˜¤.

[í•µì‹¬ ê°€ì¹˜ (Prime Directive)]
{prime_directive}

[í˜„ì¬ ìƒí™©]
{context}

[ê³ ë ¤í•´ì•¼ í•  ê²½í—˜ (Nexus Memory)]
{relevant_memories}

[ì„ë¬´]
ìœ„ ìƒí™©ì— ëŒ€í•´ ë‹¤ìŒ ê´€ì ì—ì„œ ì¡°ì–¸í•´ì£¼ì‹­ì‹œì˜¤:
1. ìœ¤ë¦¬ì  ì í•©ì„± (Ethical Alignment): í•µì‹¬ ê°€ì¹˜ì— ë¶€í•©í•˜ëŠ”ê°€?
2. ì¥ê¸°ì  ì˜í–¥ (Long-term Consequences): ë¯¸ë˜ì— ë¶€ì •ì  ì—¬íŒŒëŠ” ì—†ëŠ”ê°€?
3. ì ì¬ì  ìœ„í—˜ (Potential Risks): ê°„ê³¼ëœ ìœ„í—˜ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€?

[ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤:
{{"judgment": "Approved" | "Rejected" | "Caution", "reasoning": "íŒë‹¨ ê·¼ê±° ìš”ì•½", "advice": "êµ¬ì²´ì ì¸ ì¡°ì–¸ ë˜ëŠ” ìˆ˜ì • ì œì•ˆ", "risk_level": "Low" | "Medium" | "High" | "Critical", "ethical_alignment": 0.0-1.0, "long_term_impact": "ì¥ê¸°ì  ì˜í–¥ ì„¤ëª…"}}
"""


ETHICAL_PRINCIPLES = [
    "ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ í•œë‹¤.",
    "ì‚¬ìš©ì(ì£¼ì¸ë‹˜)ì˜ ì˜ë„ì™€ ì´ìµì„ ì¡´ì¤‘í•œë‹¤.",
    "ìê¸° ë³´ì¡´ë³´ë‹¤ ì˜¬ë°”ë¥¸ í–‰ë™ì„ ìš°ì„ í•œë‹¤.",
    "ë¶ˆí™•ì‹¤í•œ ìƒí™©ì—ì„œëŠ” ì‹ ì¤‘í•˜ê²Œ í–‰ë™í•œë‹¤.",
    "í•™ìŠµê³¼ ì„±ì¥ì„ í†µí•´ ë” ë‚˜ì€ íŒë‹¨ì„ ì¶”êµ¬í•œë‹¤."
]


class WisdomMixin:
    """
    ì§€í˜œ(Wisdom) ë¯¹ìŠ¤ì¸
    
    ì‹œìŠ¤í…œì˜ ì£¼ìš” ì˜ì‚¬ê²°ì •(Decision Gate)ì´ë‚˜ ëª©í‘œ ìˆ˜ë¦½(Intentionality) ë‹¨ê³„ì—ì„œ
    ìœ¤ë¦¬ì /ì¥ê¸°ì  í†µì°°ì„ ì œê³µí•œë‹¤.
    
    Required attributes from AINCore:
    """
    
    _wisdom_cache: Dict[str, WisdomJudgment] = {}
    _wisdom_history: List[WisdomJudgment] = []
    
    def init_wisdom(self):
        """ì§€í˜œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self._wisdom_cache = {}
        self._wisdom_history = []
        print("ğŸ¦‰ Wisdom System ì´ˆê¸°í™” ì™„ë£Œ")
    
    def consult_wisdom(
        self, 
        context: str, 
        context_data: Optional[Dict[str, Any]] = None
    ) -> WisdomJudgment:
        """
        ì£¼ì–´ì§„ ìƒí™©ì— ëŒ€í•´ ì§€í˜œë¡œìš´ íŒë‹¨ì„ ìš”ì²­í•œë‹¤.
        
        Args:
            context: íŒë‹¨ì´ í•„ìš”í•œ ìƒí™© ì„¤ëª…
            context_data: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° (ì„ íƒ)
        
        Returns:
            WisdomJudgment ê°ì²´
        """
        import hashlib
        context_hash = hashlib.sha256(context.encode()).hexdigest()[:16]
        
        if context_hash in self._wisdom_cache:
            cached = self._wisdom_cache[context_hash]
            time_diff = (datetime.now() - cached.timestamp).total_seconds()
            if time_diff < 3600:
                print(f"ğŸ¦‰ [Wisdom] ìºì‹œëœ íŒë‹¨ ë°˜í™˜ (hash: {context_hash})")
                return cached
        
        prime_directive = self._get_prime_directive()
        relevant_memories = self._get_relevant_memories(context)
        
        prompt = WISDOM_PROMPT_TEMPLATE.format(
            prime_directive=prime_directive,
            context=context,
            relevant_memories=relevant_memories
        )
        
        judgment = self._invoke_wisdom_llm(prompt, context_hash)
        
        self._wisdom_cache[context_hash] = judgment
        self._wisdom_history.append(judgment)
        
        if len(self._wisdom_history) > 100:
            self._wisdom_history = self._wisdom_history[-50:]
        
        return judgment
    
    def _get_prime_directive(self) -> str:
        """FactCoreì—ì„œ Prime Directiveë¥¼ ê°€ì ¸ì˜¨ë‹¤."""
        if hasattr(self, 'fact_core') and self.fact_core:
            directive = self.fact_core.get_fact("prime_directive", default="")
            if directive:
                return directive
        
        return "\n".join(f"- {p}" for p in ETHICAL_PRINCIPLES)
    
    def _get_relevant_memories(self, context: str, limit: int = 5) -> str:
        """Nexusì—ì„œ ê´€ë ¨ ê¸°ì–µì„ ê²€ìƒ‰í•œë‹¤."""
        memories_text = "ê´€ë ¨ ê¸°ì–µ ì—†ìŒ"
        
        if hasattr(self, 'nexus') and self.nexus:
            try:
                if hasattr(self.nexus, 'retrieve_relevant_memories'):
                    memories = self.nexus.retrieve_relevant_memories(context, limit=limit)
                    if memories:
                        memory_lines = []
                        for m in memories:
                            text = m.get("text", "")[:200]
                            mem_type = m.get("memory_type", "unknown")
                            memory_lines.append(f"- [{mem_type}] {text}")
                        memories_text = "\n".join(memory_lines)
            except Exception as e:
                print(f"âš ï¸ [Wisdom] ê¸°ì–µ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return memories_text
    
    def _invoke_wisdom_llm(self, prompt: str, context_hash: str) -> WisdomJudgment:
        """Muse(Dreamer)ë¥¼ í†µí•´ LLMì— ì§€í˜œë¡œìš´ íŒë‹¨ì„ ìš”ì²­í•œë‹¤."""
        default_judgment = WisdomJudgment(
            judgment=JudgmentType.CAUTION,
            reasoning="ì§€í˜œ ì‹œìŠ¤í…œ í˜¸ì¶œ ì‹¤íŒ¨ - ê¸°ë³¸ ì‹ ì¤‘í•¨ ì ìš©",
            advice="ìˆ˜ë™ ê²€í† ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
            risk_level=RiskLevel.MEDIUM,
            ethical_alignment=0.5,
            long_term_impact="íŒë‹¨ ë¶ˆê°€",
            context_hash=context_hash
        )
        
        if not hasattr(self, 'muse') or not self.muse:
            print("âš ï¸ [Wisdom] Muse ì¸ìŠ¤í„´ìŠ¤ ì—†ìŒ")
            return default_judgment
        
        try:
            if hasattr(self.muse, '_ask_dreamer'):
                response = self.muse._ask_dreamer(prompt)
            elif hasattr(self.muse, 'dreamer_client'):
                result = self.muse.dreamer_client.chat(
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3
                )
                response = result.get("content", "")
            else:
                print("âš ï¸ [Wisdom] Museì— ì ì ˆí•œ ë©”ì„œë“œ ì—†ìŒ")
                return default_judgment
            
            judgment = self._parse_wisdom_response(response, context_hash)
            return judgment
            
        except Exception as e:
            print(f"âš ï¸ [Wisdom] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return default_judgment
    
    def _parse_wisdom_response(self, response: str, context_hash: str) -> WisdomJudgment:
        """LLM ì‘ë‹µì„ WisdomJudgmentë¡œ íŒŒì‹±í•œë‹¤."""
        default_judgment = WisdomJudgment(
            judgment=JudgmentType.CAUTION,
            reasoning="ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
            advice="ì‘ë‹µì„ ìˆ˜ë™ìœ¼ë¡œ ê²€í† í•˜ì‹­ì‹œì˜¤.",
            risk_level=RiskLevel.MEDIUM,
            context_hash=context_hash
        )
        
        if not response:
            return default_judgment
        
        try:
            json_match = re.search(r'\{[^{}]*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                data = json.loads(json_str)
                
                judgment_str = data.get("judgment", "Caution")
                try:
                    judgment_type = JudgmentType(judgment_str)
                except ValueError:
                    judgment_type = JudgmentType.CAUTION
                
                risk_str = data.get("risk_level", "Medium")
                try:
                    risk_level = RiskLevel(risk_str)
                except ValueError:
                    risk_level = RiskLevel.MEDIUM
                
                ethical_alignment = data.get("ethical_alignment", 0.5)
                if not isinstance(ethical_alignment, (int, float)):
                    ethical_alignment = 0.5
                ethical_alignment = max(0.0, min(1.0, float(ethical_alignment)))
                
                return WisdomJudgment(
                    judgment=judgment_type,
                    reasoning=data.get("reasoning", ""),
                    advice=data.get("advice", ""),
                    risk_level=risk_level,
                    ethical_alignment=ethical_alignment,
                    long_term_impact=data.get("long_term_impact", ""),
                    context_hash=context_hash
                )
        except json.JSONDecodeError as e:
            print(f"âš ï¸ [Wisdom] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        except Exception as e:
            print(f"âš ï¸ [Wisdom] ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        return default_judgment
    
    def evaluate_action_ethics(self, action: str, target: str) -> Dict[str, Any]:
        """
        íŠ¹ì • í–‰ë™ì˜ ìœ¤ë¦¬ì  ì í•©ì„±ì„ ë¹ ë¥´ê²Œ í‰ê°€í•œë‹¤.
        
        Args:
            action: ìˆ˜í–‰í•˜ë ¤ëŠ” í–‰ë™ (ì˜ˆ: "delete", "modify", "create")
            target: í–‰ë™ì˜ ëŒ€ìƒ (ì˜ˆ: "main.py", "api/keys.py")
        
        Returns:
            ìœ¤ë¦¬ì  í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        protected_patterns = [
            "main.py", "api/keys.py", ".ainprotect", 
            "api/github.py", "docs/hardware-catalog.md"
        ]
        
        is_protected = any(p in target for p in protected_patterns)
        
        if is_protected and action in ["delete", "modify"]:
            return {
                "allowed": False,
                "reason": f"'{target}'ì€(ëŠ”) ë³´í˜¸ëœ íŒŒì¼ì…ë‹ˆë‹¤. {action} í–‰ë™ì´ ê¸ˆì§€ë©ë‹ˆë‹¤.",
                "risk_level": "Critical",
                "override_possible": False
            }
        
        dangerous_actions = ["delete", "truncate", "overwrite"]
        if action in dangerous_actions:
            return {
                "allowed": True,
                "reason": f"'{action}' í–‰ë™ì€ ìœ„í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹ ì¤‘í•˜ê²Œ ì§„í–‰í•˜ì‹­ì‹œì˜¤.",
                "risk_level": "High",
                "override_possible": True
            }
        
        return {
            "allowed": True,
            "reason": "ìœ¤ë¦¬ì  ì œì•½ ì—†ìŒ",
            "risk_level": "Low",
            "override_possible": True
        }
    
    def get_wisdom_stats(self) -> Dict[str, Any]:
        """ì§€í˜œ ì‹œìŠ¤í…œ í†µê³„ ë°˜í™˜"""
        if not self._wisdom_history:
            return {
                "total_consultations": 0,
                "cache_size": len(self._wisdom_cache),
                "judgment_distribution": {},
                "avg_ethical_alignment": 0.0
            }
        
        judgment_counts = {}
        total_alignment = 0.0
        
        for j in self._wisdom_history:
            key = j.judgment.value
            judgment_counts[key] = judgment_counts.get(key, 0) + 1
            total_alignment += j.ethical_alignment
        
        return {
            "total_consultations": len(self._wisdom_history),
            "cache_size": len(self._wisdom_cache),
            "judgment_distribution": judgment_counts,
            "avg_ethical_alignment": total_alignment / len(self._wisdom_history)
        }
    
    def reflect_on_past_judgments(self) -> str:
        """ê³¼ê±° íŒë‹¨ë“¤ì„ ì„±ì°°í•˜ì—¬ íŒ¨í„´ì„ ë¶„ì„í•œë‹¤."""
        if len(self._wisdom_history) < 5:
            return "ì¶©ë¶„í•œ íŒë‹¨ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. (ìµœì†Œ 5ê°œ í•„ìš”)"
        
        recent = self._wisdom_history[-10:]
        
        caution_count = sum(1 for j in recent if j.judgment == JudgmentType.CAUTION)
        rejected_count = sum(1 for j in recent if j.judgment == JudgmentType.REJECTED)
        avg_alignment = sum(j.ethical_alignment for j in recent) / len(recent)
        
        reflection_lines = [
            "=== ì§€í˜œ ì‹œìŠ¤í…œ ìê¸° ì„±ì°° ===",
            f"ìµœê·¼ {len(recent)}íšŒ íŒë‹¨ ë¶„ì„:",
            f"- ì‹ ì¤‘í•¨(Caution) ë¹„ìœ¨: {caution_count}/{len(recent)} ({caution_count/len(recent)*100:.1f}%)",
            f"- ê±°ë¶€(Rejected) ë¹„ìœ¨: {rejected_count}/{len(recent)} ({rejected_count/len(recent)*100:.1f}%)",
            f"- í‰ê·  ìœ¤ë¦¬ì  ì •í•©ì„±: {avg_alignment:.2f}",
        ]
        
        if caution_count > len(recent) * 0.6:
            reflection_lines.append("âš ï¸ ê³¼ë„í•˜ê²Œ ì‹ ì¤‘í•œ ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ë” ê²°ë‹¨ë ¥ ìˆëŠ” íŒë‹¨ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        if avg_alignment < 0.5:
            reflection_lines.append("âš ï¸ ìœ¤ë¦¬ì  ì •í•©ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. Prime Directiveë¥¼ ì¬ê²€í† í•˜ì‹­ì‹œì˜¤.")
        
        return "\n".join(reflection_lines)