"""
AIN Nexus Engine: μ‹μ¤ν…μ κΈ°μ–µ(Evolution History)κ³Ό λ€ν™”(Episodic Memory)λ¥Ό κ΄€λ¦¬ν•λ‹¤.

λ¨λ“ κµ¬μ΅°:

Step 4 Integration:
    Nexusλ” μ΄μ  RetrievalMixinμ„ μƒμ†λ°›μ•„ λ²΅ν„° DB(LanceDB)μ—μ„
    μλ―Έλ΅ μ  κΈ°μ–µμ„ κ²€μƒ‰ν•λ” κΈ°λ¥μ„ κ°–μ¶”κ² λμ—λ‹¤.
"""
from typing import Optional, List, Dict, Any

import pyarrow as pa

from .core import NexusCore
from .storage import load_json, save_json
from .memory import VectorMemory
from .history import HistoryManager
from .arrow import ArrowConverter
from .retrieval import RetrievalMixin


class Nexus(NexusCore, RetrievalMixin):
    """
    AINμ Nexus Engine: μ‹μ¤ν…μ κΈ°μ–µμ„ κ΄€λ¦¬ν•λ‹¤.
    
    ν•μ„ νΈν™μ„±μ„ μ„ν•΄ κΈ°μ΅΄ μΈν„°νμ΄μ¤λ¥Ό λ¨λ‘ μ μ§€ν•λ©΄μ„
    λ‚΄λ¶€μ μΌλ΅ λ¨λ“ν™”λ μ»΄ν¬λ„νΈλ¥Ό μ‚¬μ©ν•λ‹¤.
    
    Step 4 Evolution:
        RetrievalMixinμ„ μƒμ†λ°›μ•„ retrieve_relevant_memories(),
        get_recent_insights() λ“±μ μλ―Έλ΅ μ  κ²€μƒ‰ κΈ°λ¥μ„ κ°–μ¶”μ—λ‹¤.
    """
    
    EMBEDDING_DIM = 384  # ν•μ„ νΈν™μ„±
    
    def __init__(
        self, 
        memory_file: str = "evolution_history.json", 
        dialogue_file: str = "dialogue_memory.json"
    ):
        super().__init__()
        
        self.memory_file = memory_file
        self.dialogue_file = dialogue_file
        
        # λ¨λ“ν™”λ μ»΄ν¬λ„νΈ
        self._vector_memory = VectorMemory()
        self._history_manager = HistoryManager(
            memory_file=memory_file,
            dialogue_file=dialogue_file,
            vector_memory=self._vector_memory
        )
        self._arrow_converter = ArrowConverter()
        
        print("β… Nexus Engine μ΄κΈ°ν™” μ™„λ£ (RetrievalMixin ν†µν•©)")
    
    @property
    def vector_memory(self) -> VectorMemory:
        """
        RetrievalMixinμ΄ μ”κµ¬ν•λ” vector_memory ν”„λ΅νΌν‹°.
        λ‚΄λ¶€ _vector_memory μΈμ¤ν„΄μ¤λ¥Ό λ…Έμ¶ν•λ‹¤.
        """
        return self._vector_memory
    
    def record_evolution(
        self, 
        action: str, 
        file: str, 
        description: str, 
        status: str = "success",
        error: str = None
    ):
        """μ§„ν™” κΈ°λ΅ μ €μ¥ (ν•μ„ νΈν™μ„±)"""
        self._history_manager.record_evolution(
            action=action,
            file=file,
            description=description,
            status=status,
            error=error
        )
        
        # λ©”νΈλ¦­μ¤ μ—…λ°μ΄νΈ
        if status == "success":
            self.metrics["total_evolutions"] += 1
            self.metrics["growth_score"] += 10
            
            # λ λ²¨μ—… μ²΄ν¬
            new_level = 1 + (self.metrics["total_evolutions"] // 10)
            if new_level > self.metrics["level"]:
                self.metrics["level"] = new_level
                print(f"π‰ Nexus λ λ²¨ μ—…! Lv.{self.metrics['level']}")
            
            self._save_metrics()
        
        # μ΄λ²¤νΈ λ°μƒ
        self.emit("evolution_recorded", {
            "action": action,
            "file": file,
            "status": status
        })
    
    def record_conversation(self, role: str, content: str, metadata: Dict = None):
        """λ€ν™” κΈ°λ΅ μ €μ¥ (ν•μ„ νΈν™μ„±)"""
        self._history_manager.record_conversation(
            role=role,
            content=content,
            metadata=metadata
        )
    
    def get_evolution_summary(self, limit: int = 10) -> str:
        """μ§„ν™” κΈ°λ΅ μ”μ•½ (ν•μ„ νΈν™μ„±)"""
        return self._history_manager.get_evolution_summary(limit=limit)
    
    def get_recent_history(self, limit: int = 5) -> List[Dict[str, Any]]:
        """μµκ·Ό μ§„ν™” κΈ°λ΅ λ°ν™ (ν•μ„ νΈν™μ„±)"""
        return self._history_manager.get_recent_history(limit=limit)
    
    def get_dialogue_context(self, limit: int = 10) -> List[Dict[str, Any]]:
        """λ€ν™” μ»¨ν…μ¤νΈ λ°ν™ (ν•μ„ νΈν™μ„±)"""
        return self._history_manager.get_dialogue_context(limit=limit)
    
    def export_history_as_arrow(self) -> Optional[pa.Table]:
        """μ§„ν™” κΈ°λ΅μ„ Arrow Tableλ΅ μ§λ ¬ν™” (ν•μ„ νΈν™μ„±)"""
        history_cache = self._history_manager._evolution_cache
        return self._arrow_converter.export_history(history_cache)
    
    def text_to_embedding(self, text: str) -> List[float]:
        """ν…μ¤νΈλ¥Ό μ„λ² λ”© λ²΅ν„°λ΅ λ³€ν™ (ν•μ„ νΈν™μ„±)"""
        return self._vector_memory.text_to_embedding(text)
    
    def store_semantic_memory(
        self, 
        text: str, 
        memory_type: str = "evolution",
        source: str = "nexus",
        metadata: Dict[str, Any] = None
    ) -> bool:
        """μλ―Έλ΅ μ  κΈ°μ–µ μ €μ¥ (ν•μ„ νΈν™μ„±)"""
        return self._vector_memory.store(
            text=text,
            memory_type=memory_type,
            source=source,
            metadata=metadata
        )
    
    def search_semantic_memory(
        self, 
        query_text: str, 
        limit: int = 5,
        memory_type: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """μλ―Έ κΈ°λ° κΈ°μ–µ κ²€μƒ‰ (ν•μ„ νΈν™μ„±)"""
        return self._vector_memory.search(
            query_text=query_text,
            limit=limit,
            memory_type=memory_type
        )
    
    def get_memory_count(self) -> int:
        """μ €μ¥λ λ²΅ν„° κΈ°μ–µ μ (ν•μ„ νΈν™μ„±)"""
        return self._vector_memory.count()
    
    def is_vector_memory_connected(self) -> bool:
        """λ²΅ν„° λ©”λ¨λ¦¬ μ—°κ²° μƒνƒ (ν•μ„ νΈν™μ„±)"""
        return self._vector_memory.is_connected