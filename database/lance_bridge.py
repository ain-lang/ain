"""
LanceDB Vector Bridge - Step 4: Semantic Memory Store
=====================================================
AINì˜ ì˜ë¯¸ë¡ ì  ê¸°ì–µì„ ìœ„í•œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¸Œë¦¿ì§€.
LanceDBë¥¼ í†µí•´ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì €ì¥í•˜ê³ , ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰(ANN)ì„ ìˆ˜í–‰í•œë‹¤.

Architecture:
    Nexus (Application) -> LanceBridge (Driver) -> LanceDB (Storage)
"""

import os
from typing import Optional, List, Dict, Any
from datetime import datetime

# LanceDB & Arrow imports with graceful fallback
try:
    import lancedb
    import pyarrow as pa
    LANCE_AVAILABLE = True
except ImportError:
    LANCE_AVAILABLE = False
    print("âš ï¸ LanceDB ë˜ëŠ” PyArrow ë¯¸ì„¤ì¹˜. Vector Memory ë¹„í™œì„±í™”.")


class LanceBridge:
    """
    LanceDB Vector Store ì‹±ê¸€í†¤ ë¸Œë¦¿ì§€.
    
    Nexusê°€ ê¸°ì–µì„ ë²¡í„°í™”í•˜ì—¬ ì €ì¥í•˜ê³ , ì˜ë¯¸ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆê²Œ í•œë‹¤.
    Step 3ì—ì„œ í™•ë¦½ëœ Arrow ê¸°ë°˜ Zero-Copy ì›ì¹™ì„ ì¤€ìˆ˜í•œë‹¤.
    """
    
    _instance: Optional["LanceBridge"] = None
    
    # ë²¡í„° ì°¨ì› (Gemini text-embedding-004 ê¸°ì¤€)
    VECTOR_DIM = 768
    
    # ê¸°ë³¸ ì €ì¥ ê²½ë¡œ
    DEFAULT_DB_PATH = os.environ.get("LANCEDB_PATH", "/data/lancedb")
    
    def __new__(cls, db_path: str = None):
        """ì‹±ê¸€í†¤ íŒ¨í„´"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self, db_path: str = None):
        if self._initialized:
            return
        
        self._db_path = db_path or self.DEFAULT_DB_PATH
        self._db = None
        self._table = None
        self._connected = False
        
        if LANCE_AVAILABLE:
            self._connect()
        
        self._initialized = True
    
    def _connect(self) -> bool:
        """LanceDB ì—°ê²° ë° í…Œì´ë¸” ì´ˆê¸°í™”"""
        try:
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(self._db_path, exist_ok=True)

            # ì˜ì†ì„± ë§ˆì»¤ í™•ì¸ (Railway ì¬ë°°í¬ ê°ì§€)
            marker = os.path.join(self._db_path, ".persistence_marker")
            if not os.path.exists(marker):
                print("âš ï¸ ìƒˆ LanceDB ì¸ìŠ¤í„´ìŠ¤ ê°ì§€ (ì¬ë°°í¬ í›„?)")
                with open(marker, 'w') as f:
                    f.write(datetime.now().isoformat())
            else:
                with open(marker, 'r') as f:
                    created = f.read().strip()
                print(f"âœ… LanceDB ì˜ì†ì„± í™•ì¸: {created} ì´í›„ ìœ ì§€ë¨")

            # LanceDB ì—°ê²°
            self._db = lancedb.connect(self._db_path)
            
            # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ìƒì„±/ë§ˆì´ê·¸ë ˆì´ì…˜
            existing_tables = self._db.table_names()
            if "memory_bank" not in existing_tables:
                self._create_memory_table()
            else:
                self._table = self._db.open_table("memory_bank")
                # ì°¨ì› ë¶ˆì¼ì¹˜ í™•ì¸ â†’ ë§ˆì´ê·¸ë ˆì´ì…˜
                if not self._check_and_migrate_schema():
                    self._create_memory_table()
            
            self._connected = True
            print(f"âœ… LanceDB ì—°ê²° ì„±ê³µ: {self._db_path}")
            return True
            
        except Exception as e:
            print(f"âŒ LanceDB ì—°ê²° ì‹¤íŒ¨: {e}")
            self._connected = False
            return False
    
    def _create_memory_table(self):
        """ë©”ëª¨ë¦¬ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ìƒì„±"""
        # PyArrow ìŠ¤í‚¤ë§ˆ ì •ì˜
        schema = pa.schema([
            ("id", pa.string()),
            ("text", pa.string()),
            ("vector", pa.list_(pa.float32(), self.VECTOR_DIM)),
            ("memory_type", pa.string()),  # episodic, semantic, procedural
            ("source", pa.string()),
            ("timestamp", pa.string()),
            ("metadata", pa.string()),  # JSON ì§ë ¬í™”ëœ ì¶”ê°€ ì •ë³´
        ])
        
        # ì´ˆê¸° ë”ë¯¸ ë°ì´í„°ë¡œ í…Œì´ë¸” ìƒì„± (LanceDB ìš”êµ¬ì‚¬í•­)
        initial_data = pa.table({
            "id": ["init_0"],
            "text": ["AIN Memory System Initialized"],
            "vector": [[0.0] * self.VECTOR_DIM],
            "memory_type": ["system"],
            "source": ["lance_bridge"],
            "timestamp": [datetime.now().isoformat()],
            "metadata": ["{}"],
        })
        
        self._table = self._db.create_table("memory_bank", initial_data)
        print("ğŸ“¦ memory_bank í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

    def _check_and_migrate_schema(self) -> bool:
        """
        ê¸°ì¡´ í…Œì´ë¸”ì˜ ë²¡í„° ì°¨ì›ì„ í™•ì¸í•˜ê³ , ë¶ˆì¼ì¹˜ ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜.
        Returns: True if schema is OK, False if table needs recreation.
        """
        try:
            schema = self._table.schema
            vector_field = schema.field("vector")
            # list<item: float> í˜•ì‹ì—ì„œ ë¦¬ìŠ¤íŠ¸ í¬ê¸° ì¶”ì¶œ
            if hasattr(vector_field.type, 'list_size'):
                existing_dim = vector_field.type.list_size
            else:
                # ì²« ë²ˆì§¸ ë ˆì½”ë“œë¡œ í™•ì¸
                df = self._table.to_pandas()
                if len(df) > 0:
                    existing_dim = len(df.iloc[0]["vector"])
                else:
                    return True  # ë¹ˆ í…Œì´ë¸”, OK

            if existing_dim != self.VECTOR_DIM:
                print(f"âš ï¸ ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜: ê¸°ì¡´={existing_dim}, í•„ìš”={self.VECTOR_DIM}")
                print("ğŸ”„ memory_bank í…Œì´ë¸” ì¬ìƒì„± (ë§ˆì´ê·¸ë ˆì´ì…˜)...")
                self._db.drop_table("memory_bank")
                return False

            return True
        except Exception as e:
            print(f"âš ï¸ ìŠ¤í‚¤ë§ˆ í™•ì¸ ì‹¤íŒ¨: {e}")
            return True  # ì—ëŸ¬ ì‹œ ê·¸ëŒ€ë¡œ ìœ ì§€

    @property
    def is_connected(self) -> bool:
        return self._connected and self._db is not None
    
    def add_memory(
        self,
        text: str,
        vector: List[float],
        memory_type: str = "episodic",
        source: str = "unknown",
        metadata: Dict[str, Any] = None
    ) -> bool:
        """
        ìƒˆë¡œìš´ ê¸°ì–µì„ ë²¡í„° DBì— ì €ì¥í•œë‹¤.
        
        Args:
            text: ê¸°ì–µí•  í…ìŠ¤íŠ¸
            vector: í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„° (VECTOR_DIM ì°¨ì›)
            memory_type: ê¸°ì–µ ìœ í˜• (episodic, semantic, procedural)
            source: ê¸°ì–µì˜ ì¶œì²˜ (evolution, conversation ë“±)
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„° (JSON ì§ë ¬í™”ë¨)
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        if not self.is_connected:
            print("âš ï¸ LanceDB ë¯¸ì—°ê²°. ë©”ëª¨ë¦¬ ì €ì¥ ìŠ¤í‚µ.")
            return False
        
        try:
            import json
            
            # ë²¡í„° ì°¨ì› ê²€ì¦
            if len(vector) != self.VECTOR_DIM:
                print(f"âš ï¸ ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜: {len(vector)} != {self.VECTOR_DIM}")
                # íŒ¨ë”© ë˜ëŠ” íŠ¸ë ì¼€ì´ì…˜
                if len(vector) < self.VECTOR_DIM:
                    vector = vector + [0.0] * (self.VECTOR_DIM - len(vector))
                else:
                    vector = vector[:self.VECTOR_DIM]
            
            # ìƒˆ ë ˆì½”ë“œ ìƒì„±
            memory_id = f"mem_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
            
            new_data = pa.table({
                "id": [memory_id],
                "text": [text],
                "vector": [vector],
                "memory_type": [memory_type],
                "source": [source],
                "timestamp": [datetime.now().isoformat()],
                "metadata": [json.dumps(metadata or {}, ensure_ascii=False)],
            })
            
            # í…Œì´ë¸”ì— ì¶”ê°€
            self._table.add(new_data)
            print(f"ğŸ’¾ ê¸°ì–µ ì €ì¥: {memory_id} ({len(text)} chars)")
            return True
            
        except Exception as e:
            print(f"âŒ ê¸°ì–µ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def search_memory(
        self,
        query_vector: List[float],
        limit: int = 5,
        memory_type: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ê¸°ì–µì„ ê²€ìƒ‰í•œë‹¤ (ANN Search).
        
        Args:
            query_vector: ê²€ìƒ‰ ì¿¼ë¦¬ì˜ ì„ë² ë”© ë²¡í„°
            limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            memory_type: íŠ¹ì • ê¸°ì–µ ìœ í˜•ìœ¼ë¡œ í•„í„°ë§ (ì„ íƒ)
        
        Returns:
            ìœ ì‚¬í•œ ê¸°ì–µ ëª©ë¡ (ê±°ë¦¬ ìˆœ ì •ë ¬)
        """
        if not self.is_connected:
            return []
        
        try:
            import json
            
            # ë²¡í„° ì°¨ì› ë§ì¶”ê¸°
            if len(query_vector) != self.VECTOR_DIM:
                if len(query_vector) < self.VECTOR_DIM:
                    query_vector = query_vector + [0.0] * (self.VECTOR_DIM - len(query_vector))
                else:
                    query_vector = query_vector[:self.VECTOR_DIM]
            
            # ANN ê²€ìƒ‰ ì‹¤í–‰
            results = self._table.search(query_vector).limit(limit).to_pandas()
            
            # ê²°ê³¼ ë³€í™˜
            memories = []
            for _, row in results.iterrows():
                memory = {
                    "id": row["id"],
                    "text": row["text"],
                    "memory_type": row["memory_type"],
                    "source": row["source"],
                    "timestamp": row["timestamp"],
                    "metadata": json.loads(row["metadata"]) if row["metadata"] else {},
                    "distance": row.get("_distance", 0.0),
                }
                
                # í•„í„°ë§ ì ìš©
                if memory_type and memory["memory_type"] != memory_type:
                    continue
                    
                memories.append(memory)
            
            return memories
            
        except Exception as e:
            print(f"âŒ ê¸°ì–µ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_recent_memories(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ìµœê·¼ ì €ì¥ëœ ê¸°ì–µì„ ì‹œê°„ìˆœìœ¼ë¡œ ë°˜í™˜"""
        if not self.is_connected:
            return []
        
        try:
            import json
            
            # ì „ì²´ ë°ì´í„°ì—ì„œ ìµœê·¼ Nê°œ ì¶”ì¶œ
            df = self._table.to_pandas()
            df = df.sort_values("timestamp", ascending=False).head(limit)
            
            memories = []
            for _, row in df.iterrows():
                memories.append({
                    "id": row["id"],
                    "text": row["text"],
                    "memory_type": row["memory_type"],
                    "source": row["source"],
                    "timestamp": row["timestamp"],
                    "metadata": json.loads(row["metadata"]) if row["metadata"] else {},
                })
            
            return memories
            
        except Exception as e:
            print(f"âŒ ìµœê·¼ ê¸°ì–µ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def count_memories(self) -> int:
        """ì €ì¥ëœ ê¸°ì–µì˜ ì´ ê°œìˆ˜"""
        if not self.is_connected:
            return 0
        try:
            return len(self._table.to_pandas())
        except:
            return 0
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ (í˜„ì¬ LanceDBëŠ” ëª…ì‹œì  ì¢…ë£Œ ë¶ˆí•„ìš”)"""
        self._connected = False
        print("ğŸ”Œ LanceDB ì—°ê²° ì¢…ë£Œ")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ì ‘ê·¼ í—¬í¼
def get_lance_bridge() -> LanceBridge:
    """ì „ì—­ LanceBridge ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return LanceBridge()
